{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Multimodal RAG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import os\n",
    "from openai import OpenAI\n",
    "import base64\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.messages import HumanMessage\n",
    "from IPython.display import Markdown,Image,Latex, display\n",
    "import requests\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from PIL import Image\n",
    "from transformers import CLIPProcessor, CLIPModel\n",
    "import numpy as np\n",
    "import faiss\n",
    "import torch\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': 0,\n",
       " 'Question Number': 1,\n",
       " 'Share Context': 'Neshie Wakuluk is an investment strategist who develops capital market expectations for\\nan investment firm that invests across asset classes and global markets. Wakuluk started her\\ncareer when the global markets were experiencing significant volatility and poor returns; as a\\nresult, she is now careful to base her conclusions on objective evidence and analytical\\nprocedures to mitigate any potential biases.Wakuluk’s approach to economic forecasting\\nutilizes a structural model in conjunction with a diffusion index to determine the current\\nphase of a country’s business cycle. This approach has produced successful predictions in the\\npast, thus Wakuluk has high confidence in the predictions. Wakuluk also determines whether any\\nadjustments need to be made to her initial estimates of the respective aggregate economic\\ngrowth trends based on historical rates of growth for Countries X and Y (both developed\\nmarkets) and Country Z (a developing market). Exhibit 1 summarizes Wakuluk’s predictions:\\nWakuluk assumes short-term interest rates adjust with expected inflation and are procyclical.\\nWakuluk reviews the historical short-term interest rate trends for each country, which further\\nconfirms her predictions shown in Exhibit 1.Wakuluk decides to focus on Country Y to determine\\nthe path of nominal interest rates, the potential economic response of Country Y’s economy to\\nthis path, and the timing for when Country Y’s economy may move into the next business cycle.\\nWakuluk makes the following observations:Observation 1 Monetary policy has been persistently\\nloose for Country Y, while fiscal policies have been persistently tight.Observation 2 Country Y\\nis expected to significantly increase transfer payments and introduce a more progressive tax\\nregime.Observation 3 The current yield curve for Country Y suggests that the business cycle is\\nin the slowdown phase, with bond yields starting to reflect contractionary conditions.\\n ',\n",
       " 'Share Image': ['images/CapitalMarketExpectations_images/share1-8_1.png'],\n",
       " 'Question Text': 'Wakuluk most likely seeks to mitigate which of the following biases in',\n",
       " 'Image': '',\n",
       " 'Options': {'A': 'Availability', 'B': 'Time period', 'C': 'Survivorship'},\n",
       " 'Answer': 'A',\n",
       " 'Explanation': 'Wakuluk started her career when the global markets were experiencing significant\\nvolatility and poor returns. She is careful to base her conclusions on objective evidence and\\nanalytical procedures to mitigate potential biases, which suggests she is seeking to mitigate\\nan availability bias. Availability bias is the tendency to be overly influenced by events that\\nhave left a strong impression and/or for which it is easy to recall an example.',\n",
       " 'QA Type': 'Knowledge reasoning QA',\n",
       " 'Question Type': 'text+image',\n",
       " 'Level of Difficulty': 'Easy',\n",
       " 'Knowledge Topics': 'Behavioral finance, Cognitive biases, Decision-making processes',\n",
       " 'General Topics': 'Capital Market Expectations',\n",
       " 'Book Label': 'Capital Market Expectations'}"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import json\n",
    "file_path = '../dataset/multiDemo.json'\n",
    "with open(file_path, 'r') as file:\n",
    "    data = json.load(file)\n",
    "query=data[-3]\n",
    "error_log=data[0]\n",
    "error_log"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 加载CLIP模型和处理器\n",
    "model = CLIPModel.from_pretrained(\"openai/clip-vit-base-patch32\")\n",
    "processor = CLIPProcessor.from_pretrained(\"openai/clip-vit-base-patch32\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def clipEmbedding(data):\n",
    "    textdata=\"Question:\"+data.get(\"Question Text\")+ \"Options:\"+str(data.get(\"Options\"))+ \"Correct Answer:\"+data.get(\"Answer\")\n",
    "    # \"Wrong Answer:\"+data.get(\"Wrong_reasoning_steps\")+\"Feedback\"\n",
    "    if data.get(\"Image\")!='':\n",
    "        print(\"we have image\")\n",
    "        image_path = '../dataset/'+ data.get(\"Image\")\n",
    "        image = Image.open(image_path)\n",
    "        # 生成文本和图像的嵌入，添加 truncation=True 和 max_length=77\n",
    "        inputs = processor(text=[textdata], images=image, return_tensors=\"pt\", padding=True, truncation=True, max_length=77)\n",
    "        # 使用CLIP模型生成嵌入\n",
    "        outputs = model(**inputs)\n",
    "        image_embedding = outputs.image_embeds  # 图像嵌入\n",
    "        text_embedding = outputs.text_embeds  # 文本和选项嵌入\n",
    "        \n",
    "    else:\n",
    "        # print(\"No image provided.\")  # 如果没有提供图片，打印提示\n",
    "        # 如果没有图像，生成文本嵌入\n",
    "        inputs = processor(text=[textdata], return_tensors=\"pt\", padding=True, truncation=True, max_length=77)\n",
    "        text_embedding = model.get_text_features(**inputs)\n",
    "        # 创建一个与图像嵌入维度相同的零向量\n",
    "        image_embedding = torch.zeros((text_embedding.shape[0], 512))  # 假设图像嵌入维度是512\n",
    "    combined_embedding = torch.cat((text_embedding, image_embedding), dim=-1) # 将文本和图像嵌入连接在一起\n",
    "    return combined_embedding\n",
    "\n",
    "\n",
    "# 获取嵌入的维度\n",
    "embedding_dim = clipEmbedding(error_log).shape[1]  # 嵌入的最后一个维度表示向量维度\n",
    "index = faiss.IndexFlatL2(embedding_dim)  # 使用 L2 距离度量\n",
    "# 将生成的多模态嵌入添加到 Faiss 中\n",
    "index.add(clipEmbedding(error_log).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 获取嵌入的维度\n",
    "embedding_dim = clipEmbedding(error_log).shape[1]  # 嵌入的最后一个维度表示向量维度\n",
    "index = faiss.IndexFlatL2(embedding_dim)  # 使用 L2 距离度量\n",
    "# 将生成的多模态嵌入添加到 Faiss 中\n",
    "index.add(clipEmbedding(error_log).detach().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in the index: 1\n"
     ]
    }
   ],
   "source": [
    "# 查看Faiss索引中存储的向量数量\n",
    "print(\"Number of vectors in the index:\", index.ntotal)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "we have image\n",
      "Distances to closest vectors: [[92.592575]]\n",
      "Indices of closest vectors: [[0]]\n"
     ]
    }
   ],
   "source": [
    "# 假设我们有一个查询向量 query_embedding\n",
    "query_embedding = clipEmbedding(query).detach().numpy()\n",
    "\n",
    "# 检索 Faiss 中最相似的 k 个向量\n",
    "k = 1  # 你希望检索到最相似的 1 个向量\n",
    "D, I = index.search(query_embedding, k)\n",
    "\n",
    "# D 是距离，I 是对应向量的索引\n",
    "print(\"Distances to closest vectors:\", D)\n",
    "print(\"Indices of closest vectors:\", I)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 余弦相似度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "import faiss\n",
    "import numpy as np\n",
    "\n",
    "def clipEmbedding(data):\n",
    "    textdata = \"Question:\" + data.get(\"Question Text\") + \" Options:\" + str(data.get(\"Options\")) + \" Correct Answer:\" + data.get(\"Answer\")\n",
    "    \n",
    "    # 检查是否有图片\n",
    "    if data.get(\"Image\") != '':\n",
    "        image_path = '../dataset/' + data.get(\"Image\")\n",
    "        image = Image.open(image_path)\n",
    "        \n",
    "        # 生成文本和图像的嵌入，添加 truncation=True 和 max_length=77\n",
    "        inputs = processor(text=[textdata], images=image, return_tensors=\"pt\", padding=True, truncation=True, max_length=77)\n",
    "        \n",
    "        # 使用CLIP模型生成嵌入\n",
    "        outputs = model(**inputs)\n",
    "        image_embedding = outputs.image_embeds  # 图像嵌入\n",
    "        text_embedding = outputs.text_embeds  # 文本嵌入\n",
    "    else:\n",
    "        # 如果没有图像，生成文本嵌入\n",
    "        inputs = processor(text=[textdata], return_tensors=\"pt\", padding=True, truncation=True, max_length=77)\n",
    "        text_embedding = model.get_text_features(**inputs)\n",
    "        \n",
    "        # 创建一个与图像嵌入维度相同的零向量\n",
    "        image_embedding = torch.zeros((text_embedding.shape[0], 512))  # 假设图像嵌入维度是512\n",
    "    \n",
    "    # 将文本和图像嵌入拼接在一起\n",
    "    combined_embedding = torch.cat((text_embedding, image_embedding), dim=-1)\n",
    "    \n",
    "    return combined_embedding\n",
    "\n",
    "\n",
    "def normalize(embeddings):\n",
    "    # 归一化函数，计算余弦相似度时将向量进行归一化\n",
    "    norms = torch.norm(embeddings, dim=1, keepdim=True)  # 计算每个向量的范数\n",
    "    return embeddings / norms  # 将向量归一化，使其范数变为1\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors in the index: 99\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for error_log in data:\n",
    "    # 生成嵌入\n",
    "    error_log_embedding = clipEmbedding(error_log)\n",
    "\n",
    "    # 对嵌入进行归一化，以便计算余弦相似度\n",
    "    error_log_embedding = normalize(error_log_embedding)\n",
    "\n",
    "    # 获取嵌入的维度\n",
    "    embedding_dim = error_log_embedding.shape[1]  # 嵌入的维度是最后一个维度\n",
    "    if index.ntotal==0:\n",
    "        # 初始化 Faiss 索引，使用内积 (dot product) 作为距离度量\n",
    "        index = faiss.IndexFlatIP(embedding_dim)  # 使用内积度量\n",
    "\n",
    "    # 将生成的多模态嵌入转换为numpy数组并添加到Faiss索引中\n",
    "    error_log_embedding_np = error_log_embedding.detach().numpy()  # 确保转换为numpy格式\n",
    "    index.add(error_log_embedding_np)  # 将嵌入添加到Faiss索引中\n",
    "\n",
    "    # 检查索引中存储的向量数量\n",
    "print(\"Number of vectors in the index:\", index.ntotal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarities: [[0.99999976 0.89624727 0.86308324 0.8596045  0.8551398 ]]\n",
      "Indices of closest vectors: [[96 95 84 74 90]]\n"
     ]
    }
   ],
   "source": [
    "# 查询函数\n",
    "def query_embedding_faiss(query_data, index, k=5):\n",
    "    # 生成查询嵌入\n",
    "    query_embedding = clipEmbedding(query_data)\n",
    "    query_embedding = normalize(query_embedding)  # 归一化查询向量\n",
    "    \n",
    "    # 转换为 numpy 格式\n",
    "    query_embedding_np = query_embedding.detach().numpy()\n",
    "    \n",
    "    # 检索 Faiss 中与查询向量最相似的 k 个向量\n",
    "    D, I = index.search(query_embedding_np, k)  # D 是余弦相似度，I 是对应的索引\n",
    "    \n",
    "    print(\"Cosine Similarities:\", D)  # 打印查询到的余弦相似度\n",
    "    print(\"Indices of closest vectors:\", I)  # 打印最相似向量的索引\n",
    "    \n",
    "    return D, I\n",
    "\n",
    "\n",
    "# 查询最相似的5个嵌入\n",
    "D, I = query_embedding_faiss(query, index, k=5)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "96"
      ]
     },
     "execution_count": 149,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "I[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': 2270,\n",
       " 'Question Number': 107,\n",
       " 'Share Context': '',\n",
       " 'Share Image': '',\n",
       " 'Question Text': 'Consider the expected returns and standard deviations for the following portfolios:',\n",
       " 'Image': 'images/Foundationofriskmanagement1_images/107u.png',\n",
       " 'Options': {'A': ' Portfolio 1',\n",
       "  'B': ' Portfolio 2',\n",
       "  'C': ' Portfolio 3',\n",
       "  'D': ' Portfolio 4'},\n",
       " 'Answer': 'A',\n",
       " 'Explanation': 'Portfolio 1 is not efficient because it has a lower expected return and higher risk than Portfolios 2, 3, and 4. The portfolio is not mean variance efficient due to its suboptimal risk-return profile.',\n",
       " 'QA Type': 'Knowledge reasoning QA',\n",
       " 'Question Type': 'text+image',\n",
       " 'Level of Difficulty': 'Easy',\n",
       " 'Knowledge Topics': 'mean variance efficiency, portfolio analysis',\n",
       " 'General Topics': 'Foundation of Risk Management',\n",
       " 'Book Label': 'foundation of risk management1'}"
      ]
     },
     "execution_count": 125,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ID': 2266,\n",
       " 'Question Number': 103,\n",
       " 'Share Context': '',\n",
       " 'Share Image': '',\n",
       " 'Question Text': 'Which of the following portfolios falls below the Markowitz efficient frontier?',\n",
       " 'Image': 'images/Foundationofriskmanagement1_images/103u.png',\n",
       " 'Options': {'A': ' Portfolio A',\n",
       "  'B': ' Portfolio B',\n",
       "  'C': ' Portfolio C',\n",
       "  'D': ' Portfolio D'},\n",
       " 'Answer': 'B',\n",
       " 'Explanation': 'Portfolio B is inefficient (falls below the efficient frontier) because for the same risk level (8.7%), you could have portfolio C with a higher expected return (15.1% versus 14.2%). This makes portfolio B suboptimal for the given risk-return profile.',\n",
       " 'QA Type': 'Knowledge reasoning QA',\n",
       " 'Question Type': 'text+image',\n",
       " 'Level of Difficulty': 'Easy',\n",
       " 'Knowledge Topics': 'Markowitz efficient frontier, portfolio theory',\n",
       " 'General Topics': 'Foundation of Risk Management',\n",
       " 'Book Label': 'foundation of risk management1'}"
      ]
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[I[0][1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of vectors after reset: 0\n"
     ]
    }
   ],
   "source": [
    "# 清空Faiss索引中的所有向量\n",
    "index.reset()\n",
    "\n",
    "# 检查索引是否清空\n",
    "print(\"Number of vectors after reset:\", index.ntotal)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
